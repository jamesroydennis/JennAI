{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# JennAI Project Boilerplate Notebook\n",
    "\n",
    "This notebook provides a boilerplate setup for interacting with the `JennAI` monorepo project structure.\n",
    "It demonstrates how to correctly configure paths, initialize logging, access configuration, utilize the dependency injection container, and integrate with project sub-layers (business, data, presentation), and interact with the Gemini API."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Environment Setup & Path Configuration\n",
    "\n",
    "It's crucial that the notebook can correctly import modules from your `config/`, `core/`, and `project/` directories. This cell ensures the `JennAI` project root is added to `sys.path`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Determine the JennAI project root dynamically\n",
    "# Assumes this notebook is run from within the JennAI project or a subdirectory.\n",
    "# It will navigate up until it finds a marker file like 'main.py' or 'environment.yaml'\n",
    "# or if placed directly at root, it will be Path(__file__).resolve().parent\n",
    "\n",
    "current_notebook_path = Path(__file__).resolve()\n",
    "jennai_root = current_notebook_path\n",
    "while not (jennai_root / 'main.py').exists() and not (jennai_root / 'environment.yaml').exists() and jennai_root.parent != jennai_root:\n",
    "    jennai_root = jennai_root.parent\n",
    "\n",
    "if str(jennai_root) not in sys.path:\n",
    "    sys.path.insert(0, str(jennai_root)) # Insert at the beginning for higher priority\n",
    "\n",
    "print(f\"JennAI project root set to: {jennai_root}\")\n",
    "print(f\"Current sys.path: {sys.path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Core Utilities: Logging & Configuration\n",
    "\n",
    "Initialize the `loguru` logger and access global configuration settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the logging setup from config\n",
    "from config.loguru_setup import setup_logging\n",
    "from config.config import DEBUG_MODE # Assuming config.py has DEBUG_MODE\n",
    "\n",
    "# Setup logging for the notebook session\n",
    "# The log file will be created in JennAI/logs/jennai.log (relative to jennai_root)\n",
    "setup_logging(debug_mode=DEBUG_MODE)\n",
    "from loguru import logger\n",
    "\n",
    "logger.info(f\"Notebook Logging initialized. Running in DEBUG_MODE: {DEBUG_MODE}\")\n",
    "logger.debug(\"This is a debug message from the notebook.\")\n",
    "logger.warning(\"This is a warning message from the notebook.\")\n",
    "\n",
    "print(f\"Debug mode from config: {DEBUG_MODE}\")\n",
    "print(f\"Check your JennAI/logs/jennai.log file for these messages.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Dependency Injection Setup\n",
    "\n",
    "Instantiate and register simple dependencies using the `DependencyContainer`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from core.dependency_container import DependencyContainer\n",
    "\n",
    "class MockService:\n",
    "    def __init__(self, name=\"DefaultMock\"):\n",
    "        self.name = name\n",
    "        logger.info(f\"MockService '{self.name}' initialized.\")\n",
    "\n",
    "    def do_work(self):\n",
    "        logger.info(f\"MockService '{self.name}' doing some work.\")\n",
    "        return f\"Work done by {self.name}\"\n",
    "\n",
    "global_container = DependencyContainer()\n",
    "logger.info(\"Global DependencyContainer instantiated.\")\n",
    "\n",
    "# Register a dependency\n",
    "global_container.register(\"mock_service\", lambda: MockService(\"MyNotebookService\"))\n",
    "logger.info(\"Registered 'mock_service' with DependencyContainer.\")\n",
    "\n",
    "# Resolve the dependency\n",
    "resolved_service = global_container.resolve(\"mock_service\")\n",
    "logger.info(f\"Resolved 'mock_service': {resolved_service.name}\")\n",
    "print(resolved_service.do_work())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Gemini API Integration\n",
    "\n",
    "Demonstrate importing and a placeholder for using the `gemini_api` module. Remember to set your `GOOGLE_API_KEY` environment variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from config.gemini_api import AIGenerator # Assuming AIGenerator is defined here\n",
    "\n",
    "# Placeholder for your Google API Key\n",
    "google_api_key = os.getenv(\"GOOGLE_API_KEY\")\n",
    "if not google_api_key:\n",
    "    logger.warning(\"GOOGLE_API_KEY environment variable not set. Gemini API calls will fail.\")\n",
    "    # As a fallback for demonstration or if running outside proper env vars\n",
    "    # You might temporarily set it here for testing, but remove for production!\n",
    "    # google_api_key = \"YOUR_ACTUAL_API_KEY_HERE\"\n",
    "else:\n",
    "    logger.info(\"GOOGLE_API_KEY successfully loaded from environment.\")\n",
    "\n",
    "\n",
    "# Example: Register AIGenerator with the DependencyContainer\n",
    "try:\n",
    "    global_container.register(AIGenerator, lambda: AIGenerator(api_key=google_api_key))\n",
    "    logger.info(\"AIGenerator registered with DependencyContainer.\")\n",
    "    \n",
    "    # Resolve and use (example placeholder)\n",
    "    gemini_instance = global_container.resolve(AIGenerator)\n",
    "    logger.info(\"Resolved AIGenerator instance.\")\n",
    "    print(\"Gemini API (AIGenerator) configured and accessible through dependency injection.\")\n",
    "    # print(gemini_instance.generate_content(\"Hello, AI!\")) # Uncomment to test actual API call\n",
    "except Exception as e:\n",
    "    logger.error(f\"Failed to register/resolve AIGenerator: {e}\")\n",
    "    print(f\"Gemini API setup failed: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Interacting with Project Sub-Layers (Business, Data, Presentation)\n",
    "\n",
    "Demonstrate how to import and interact with modules from your `project/` subdirectories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Importing from project/business\n",
    "# Assuming you have a dummy module like project/business/some_logic.py\n",
    "try:\n",
    "    # from project.business.some_logic import BusinessProcessor\n",
    "    # processor = BusinessProcessor()\n",
    "    # processor.process_data()\n",
    "    logger.info(\"Successfully accessed project.business (placeholder).\")\n",
    "    print(\"Accessed project.business layer (conceptually).\")\n",
    "except ImportError:\n",
    "    logger.warning(\"project.business.some_logic not found. This is a placeholder import.\")\n",
    "    print(\"project.business layer placeholder.\")\n",
    "\n",
    "# Example: Importing from project/data\n",
    "# Assuming you have a dummy module like project/data/data_loader.py\n",
    "try:\n",
    "    # from project.data.data_loader import DataLoader\n",
    "    # loader = DataLoader()\n",
    "    # data = loader.load_source()\n",
    "    logger.info(\"Successfully accessed project.data (placeholder).\")\n",
    "    print(\"Accessed project.data layer (conceptually).\")\n",
    "except ImportError:\n",
    "    logger.warning(\"project.data.data_loader not found. This is a placeholder import.\")\n",
    "    print(\"project.data layer placeholder.\")\n",
    "\n",
    "# Example: Importing from project/presentation\n",
    "# Assuming you have a dummy module like project/presentation/ui_handler.py\n",
    "try:\n",
    "    # from project.presentation.ui_handler import UIHandler\n",
    "    # handler = UIHandler()\n",
    "    # handler.render_view()\n",
    "    logger.info(\"Successfully accessed project.presentation (placeholder).\")\n",
    "    print(\"Accessed project.presentation layer (conceptually).\")\n",
    "except ImportError:\n",
    "    logger.warning(\"project.presentation.ui_handler not found. This is a placeholder import.\")\n",
    "    print(\"project.presentation layer placeholder.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Interactive Testing / Verification\n",
    "\n",
    "While `pytest` is for formal tests, notebooks are great for quick, interactive verification. Here, we can re-run parts of our `test_cuda.py` logic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "print(\"--- Running Interactive CUDA Verification ---\")\n",
    "is_cuda_available = torch.cuda.is_available()\n",
    "print(f\"Is CUDA available: {is_cuda_available}\")\n",
    "\n",
    "if is_cuda_available:\n",
    "    print(f\"CUDA device count: {torch.cuda.device_count()}\")\n",
    "    print(f\"Current CUDA device: {torch.cuda.current_device()}\")\n",
    "    print(f\"CUDA device name: {torch.cuda.get_device_name(0)}\")\n",
    "    logger.success(\"CUDA is successfully available from the notebook!\")\n",
    "    \n",
    "    # Optional: Basic GPU tensor operation to confirm functionality\n",
    "    try:\n",
    "        tensor_on_gpu = torch.rand(3, 3, device='cuda')\n",
    "        print(f\"Successfully created tensor on GPU: {tensor_on_gpu.device}\")\n",
    "        logger.debug(\"GPU tensor creation successful.\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Failed to create tensor on GPU: {e}\")\n",
    "        print(f\"Failed to create tensor on GPU: {e}\")\n",
    "else:\n",
    "    logger.warning(\"CUDA is not available. GPU-dependent operations will not work.\")\n",
    "    print(\"CUDA is NOT available.\")\n",
    "\n",
    "print(\"--- Interactive CUDA Verification Complete ---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Cleanup / Final Notes\n",
    "\n",
    "Remember to deactivate your Conda environment when you're done working in the terminal, or simply close Jupyter Lab.\n",
    "\n",
    "This boilerplate should give you a strong starting point for interactive development within your JennAI monorepo!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (JennAI Root)",
   "language": "python",
   "name": "jennai-root"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
